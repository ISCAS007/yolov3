[net]
# Testing
#batch=1
#subdivisions=1
# Training
batch=16
subdivisions=1
width=416
height=416
channels=3
momentum=0.9
decay=0.0005
angle=0
saturation = 1.5
exposure = 1.5
hue=.1

learning_rate=0.001
burn_in=1000
max_batches = 500200
policy=steps
steps=400000,450000
scales=.1,.1

# layer1 output: B,64,32a,32a idx: 0
[convolutional]
filters=64
size=3
stride=1
pad=1
activation=relu

[convolutional]
filters=64
size=3
stride=1
pad=1
activation=relu

# layer2 output: B,64,16a,16a idx: 2
[maxpool]
size=2
stride=2

[convolutional]
filters=128
size=3
stride=1
pad=1
activation=relu

[convolutional]
filters=128
size=3
stride=1
pad=1
activation=relu

# layer3 output: B,128,8a,8a idx:5
[maxpool]
size=2
stride=2

[convolutional]
filters=256
size=3
stride=1
pad=1
activation=relu

[convolutional]
filters=256
size=3
stride=1
pad=1
activation=relu

[convolutional]
filters=256
size=3
stride=1
pad=1
activation=relu

# layer4 output: B,256,4a,4a idx:9
[maxpool]
size=2
stride=2

[convolutional]
filters=512
size=3
stride=1
pad=1
activation=relu

[convolutional]
filters=512
size=3
stride=1
pad=1
activation=relu

[convolutional]
filters=512
size=3
stride=1
pad=1
activation=relu

# layer5 output: B,512,2a,2a idx:13
[maxpool]
size=2
stride=2

[convolutional]
filters=512
size=3
stride=1
pad=1
activation=relu

[convolutional]
filters=512
size=3
stride=1
pad=1
activation=relu

[convolutional]
filters=512
size=3
stride=1
pad=1
activation=relu

# layer6 output: B,512,a,a idx:17
[maxpool]
size=2
stride=2

[convolutional]
batch_normalize=1
size=3
stride=1
pad=1
filters=1024
activation=leaky

[convolutional]
size=1
stride=1
pad=1
filters=255
activation=linear

# idx: 20
[yolo]
mask = 6,7,8
anchors = 10,13,  16,30,  33,23,  30,61,  62,45,  59,119,  116,90,  156,198,  373,326
classes=80
num=9
jitter=.3
ignore_thresh = .7
truth_thresh = 1
random=1

# B,512,a,a
[route]
layers = -4

[convolutional]
batch_normalize=1
filters=512
size=1
stride=1
pad=1
activation=leaky

[upsample]
stride=2

# B,512,2a,2a
[route]
layers = -1, -8



[convolutional]
batch_normalize=1
filters=256
size=1
stride=1
pad=1
activation=leaky

[convolutional]
batch_normalize=1
size=3
stride=1
pad=1
filters=512
activation=leaky

[convolutional]
batch_normalize=1
filters=256
size=1
stride=1
pad=1
activation=leaky

[convolutional]
batch_normalize=1
size=3
stride=1
pad=1
filters=512
activation=leaky

[convolutional]
batch_normalize=1
filters=256
size=1
stride=1
pad=1
activation=leaky

[convolutional]
batch_normalize=1
size=3
stride=1
pad=1
filters=512
activation=leaky

[convolutional]
size=1
stride=1
pad=1
filters=255
activation=linear


[yolo]
mask = 3,4,5
anchors = 10,13,  16,30,  33,23,  30,61,  62,45,  59,119,  116,90,  156,198,  373,326
classes=80
num=9
jitter=.3
ignore_thresh = .7
truth_thresh = 1
random=1



[route]
layers = -4

[convolutional]
batch_normalize=1
filters=512
size=1
stride=1
pad=1
activation=leaky

[upsample]
stride=2

# B,512,4a,4a
[route]
layers = -1, 12



[convolutional]
batch_normalize=1
filters=128
size=1
stride=1
pad=1
activation=leaky

[convolutional]
batch_normalize=1
size=3
stride=1
pad=1
filters=256
activation=leaky

[convolutional]
batch_normalize=1
filters=128
size=1
stride=1
pad=1
activation=leaky

[convolutional]
batch_normalize=1
size=3
stride=1
pad=1
filters=256
activation=leaky

[convolutional]
batch_normalize=1
filters=128
size=1
stride=1
pad=1
activation=leaky

[convolutional]
batch_normalize=1
size=3
stride=1
pad=1
filters=256
activation=leaky

[convolutional]
size=1
stride=1
pad=1
filters=255
activation=linear


[yolo]
mask = 0,1,2
anchors = 10,13,  16,30,  33,23,  30,61,  62,45,  59,119,  116,90,  156,198,  373,326
classes=80
num=9
jitter=.3
ignore_thresh = .7
truth_thresh = 1
random=1
